{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eaca0d5",
   "metadata": {},
   "source": [
    "# Handwritten digits classification using a Neural Network\n",
    "<br>\n",
    "<img src=\"https://miro.medium.com/max/800/1*LyRlX__08q40UJohhJG9Ow.png\" align=\"left\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6383acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a change!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74aed52",
   "metadata": {},
   "source": [
    "## Libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b54699b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\domin\\Desktop\\Data_Analytics\\Exercise_SW12\n"
     ]
    }
   ],
   "source": [
    "# Required libraries:\n",
    "# !pip install tensorflow\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Current working directory\n",
    "print('Current working directory:', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c0d6c",
   "metadata": {},
   "source": [
    "## Prepare the data (MNIST dataset)\n",
    "For details of the data see: https://en.wikipedia.org/wiki/MNIST_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55992e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# The data, split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "X_test = X_test.astype(\"float32\") / 255\n",
    "\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "print(X_train.shape[0], \"train samples\")\n",
    "print(X_test.shape[0], \"test samples\")\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ba4128",
   "metadata": {},
   "source": [
    "## Show single handwritten digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d0eb78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = X_train[43] # Change index to show other digits\n",
    "fig = plt.figure\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b6f6af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of a single image\n",
    "X_train[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a507e",
   "metadata": {},
   "source": [
    "## Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c0cc3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 13, 13, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 5, 5, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2c1d03",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf93a33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "422/422 [==============================] - 18s 42ms/step - loss: 0.3723 - accuracy: 0.8863 - val_loss: 0.0824 - val_accuracy: 0.9773\n",
      "Epoch 2/5\n",
      "422/422 [==============================] - 18s 42ms/step - loss: 0.1126 - accuracy: 0.9656 - val_loss: 0.0557 - val_accuracy: 0.9855\n",
      "Epoch 3/5\n",
      "422/422 [==============================] - 20s 46ms/step - loss: 0.0849 - accuracy: 0.9742 - val_loss: 0.0443 - val_accuracy: 0.9877\n",
      "Epoch 4/5\n",
      "422/422 [==============================] - 18s 43ms/step - loss: 0.0717 - accuracy: 0.9783 - val_loss: 0.0436 - val_accuracy: 0.9890\n",
      "Epoch 5/5\n",
      "422/422 [==============================] - 17s 41ms/step - loss: 0.0608 - accuracy: 0.9812 - val_loss: 0.0384 - val_accuracy: 0.9903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19ad9ba7850>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the batch size and number of epochs\n",
    "# Note:\n",
    "# The batch size is a number of samples processed \n",
    "# before the model is updated. The number of epochs \n",
    "# is the number of complete passes through the training \n",
    "# dataset. The size of a batch must be more than or equal \n",
    "# to one and less than or equal to the number of samples \n",
    "# in the training dataset.\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "# Train the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93da0e19",
   "metadata": {},
   "source": [
    "## Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64229ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9877\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy based on the test data\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test accuracy: {score[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c898470e",
   "metadata": {},
   "source": [
    "### Jupyter notebook --footer info-- (please always provide this at the end of each submitted notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c357eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "NT\n",
      "Windows | 10\n",
      "Datetime: 2022-12-09 16:21:20\n",
      "Python Version: 3.9.13\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import socket\n",
    "from platform import python_version\n",
    "from datetime import datetime\n",
    "\n",
    "print('-----------------------------------')\n",
    "print(os.name.upper())\n",
    "print(platform.system(), '|', platform.release())\n",
    "print('Datetime:', datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print('Python Version:', python_version())\n",
    "print('-----------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('daenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "12cd337ad4cf3a097e1b5acc6eb3a384d88d11f92dcb71b7ec0b239f674608dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
